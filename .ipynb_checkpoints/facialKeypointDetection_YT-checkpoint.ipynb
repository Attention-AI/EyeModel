{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFPOQDJvuWT0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facialKeypointDetection_YT.ipynb\n",
      "training.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "The system cannot find the path specified.\n",
      "The system cannot find the path specified.\n",
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-81e37d072cec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'apt-get update -qq 2>&1 > /dev/null'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'apt-get -y install -qq google-drive-ocamlfuse fuse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# RUN THIS ONLY IF YOU ARE IN GOOGLE COLAB NOTEBOOK\n",
    "!ls\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "\n",
    "\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "\n",
    "import os\n",
    "os.chdir(\"drive/folder_name_where_this_file_is_saved\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBnD3V2CuaD5"
   },
   "outputs": [],
   "source": [
    "#####  LOADING AND EXTRACTING DATA   #####\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "def data_loader():\n",
    "    \n",
    "    # Load dataset file\n",
    "    data_frame = pd.read_csv('training.csv')\n",
    "    \n",
    "    data_frame['Image'] = data_frame['Image'].apply(lambda i: np.fromstring(i, sep=' '))\n",
    "    data_frame = data_frame.dropna()  # Get only the data with 15 keypoints\n",
    "   \n",
    "    # Extract Images pixel values\n",
    "    imgs_array = np.vstack(data_frame['Image'].values)/ 255.0\n",
    "    imgs_array = imgs_array.astype(np.float32)    # Normalize, target values to (0, 1)\n",
    "    imgs_array = imgs_array.reshape(-1, 96, 96, 1)\n",
    "        \n",
    "    # Extract labels (key point cords)\n",
    "    labels_array = data_frame[data_frame.columns[:-1]].values\n",
    "    labels_array = (labels_array - 48) / 48    # Normalize, traget cordinates to (-1, 1)\n",
    "    labels_array = labels_array.astype(np.float32) \n",
    "    \n",
    "    # shuffle the train data\n",
    "#     imgs_array, labels_array = shuffle(imgs_array, labels_array, random_state=9)  \n",
    "    \n",
    "    return imgs_array, labels_array\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "# # This snippet is just to check/verify data\n",
    "# imgs, labels = data_loader()\n",
    "# print(imgs.shape)\n",
    "# print(labels.shape)\n",
    "\n",
    "# n=0\n",
    "# labels[n] = (labels[n]*48)+48\n",
    "# image = np.squeeze(imgs[n])\n",
    "# plt.imshow(image, cmap='gray')\n",
    "# plt.plot(labels[n][::2], labels[n][1::2], 'ro')\n",
    "# plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_mj1zTvuwue"
   },
   "outputs": [],
   "source": [
    "######   BUILD, TRAIN AND SAVE THE CONVOLUTIONAL MODEL    ########\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, Activation\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "# from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# Main model\n",
    "def the_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, (3,3), padding='same', activation='relu', input_shape=X_train.shape[1:])) # Input shape: (96, 96, 1)\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    \n",
    "    # Convert all values to 1D array\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(30))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "X_train, y_train = data_loader()\n",
    "print(\"Training datapoint shape: X_train.shape:{}\".format(X_train.shape))\n",
    "print(\"Training labels shape: y_train.shape:{}\".format(y_train.shape))\n",
    "\n",
    "\n",
    "epochs = 60\n",
    "batch_size = 64\n",
    "\n",
    "model = the_model()\n",
    "hist = History()\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='checkpoint1.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# Complie Model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "model_fit = model.fit(X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, hist], verbose=1)\n",
    "\n",
    "model.save('model1.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QzUVeVykvF6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'model1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5031ab97ad43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Load the saved model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model1.h5'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# <-- Saved model path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_supported_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh5dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'write'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\io_utils.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_is_path_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'model1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "#####  TEST YOUR IMAGE FILE WITH THE MODEL  #####\n",
    "\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load the saved model\n",
    "from keras.models import load_model\n",
    "model = load_model('model1.h5')  # <-- Saved model path\n",
    "\n",
    "\n",
    "def detect_points(face_img):\n",
    "    me  = np.array(face_img)/255\n",
    "    x_test = np.expand_dims(me, axis=0)\n",
    "    x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "    y_test = model.predict(x_test)\n",
    "    label_points = (np.squeeze(y_test)*48)+48 \n",
    "    \n",
    "    return label_points\n",
    "    \n",
    "# Load haarcascade\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "dimensions = (96, 96)\n",
    "\n",
    "# Enter the path to your test image\n",
    "img = cv2.imread('you_test_image.jpg')\n",
    "\n",
    "default_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray_img, 1.3, 5)\n",
    "# faces = face_cascade.detectMultiScale(gray_img, 4, 6)\n",
    "\n",
    "faces_img = np.copy(gray_img)\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "\n",
    "all_x_cords = []\n",
    "all_y_cords = []\n",
    "\n",
    "for i, (x,y,w,h) in enumerate(faces):\n",
    "    \n",
    "    h += 10\n",
    "    w += 10\n",
    "    x -= 5\n",
    "    y -= 5\n",
    "    \n",
    "    just_face = cv2.resize(gray_img[y:y+h,x:x+w], dimensions)\n",
    "    cv2.rectangle(faces_img,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "    \n",
    "    scale_val_x = w/96\n",
    "    scale_val_y = h/96\n",
    "    \n",
    "    label_point = detect_points(just_face)\n",
    "    all_x_cords.append((label_point[::2]*scale_val_x)+x)\n",
    "    all_y_cords.append((label_point[1::2]*scale_val_y)+y)\n",
    "   \n",
    "   \n",
    "    plt.imshow(just_face, cmap='gray')\n",
    "    plt.plot(label_point[::2], label_point[1::2], 'ro', markersize=5)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plt.imshow(default_img)    \n",
    "plt.plot(all_x_cords, all_y_cords, 'wo',  markersize=3)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i9PJngooxW2f"
   },
   "outputs": [],
   "source": [
    "####  TEST YOUR VIDEO FILE WITH THE MODEL  #####\n",
    "\n",
    "\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "model = load_model('model1.h5')  # <-- Saved model path\n",
    "\n",
    "\n",
    "# input video file path\n",
    "input_file = 'testVideo.mp4'\n",
    "\n",
    "\n",
    "# output file path\n",
    "output_filename = 'testVideo_out.avi'  \n",
    "\n",
    "\n",
    "def get_points_main(img):\n",
    "\n",
    "    def detect_points(face_img):\n",
    "        me  = np.array(face_img)/255\n",
    "        x_test = np.expand_dims(me, axis=0)\n",
    "        x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "        y_test = model.predict(x_test)\n",
    "        label_points = (np.squeeze(y_test)*48)+48\n",
    "\n",
    "\n",
    "        return label_points\n",
    "\n",
    "    # load haarcascade\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    dimensions = (96, 96)\n",
    "\n",
    "\n",
    "    try:\n",
    "        default_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        gray_img = cv2.cvtColor(default_img, cv2.COLOR_RGB2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray_img, 1.3, 5)\n",
    "#         faces = face_cascade.detectMultiScale(gray_img, 4, 6)\n",
    "\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "    faces_img = np.copy(gray_img)\n",
    "\n",
    "    plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "\n",
    "    all_x_cords = []\n",
    "    all_y_cords = []\n",
    "\n",
    "\n",
    "    for i, (x,y,w,h) in enumerate(faces):\n",
    "\n",
    "        h += 10\n",
    "        w += 10\n",
    "        x -= 5\n",
    "        y -= 5\n",
    "\n",
    "        try:\n",
    "            just_face = cv2.resize(gray_img[y:y+h,x:x+w], dimensions)\n",
    "        except:\n",
    "            return []\n",
    "        cv2.rectangle(faces_img,(x,y),(x+w,y+h),(255,0,0),1)\n",
    "\n",
    "        scale_val_x = w/96\n",
    "        scale_val_y = h/96\n",
    "\n",
    "        label_point = detect_points(just_face)\n",
    "\n",
    "        all_x_cords.append((label_point[::2]*scale_val_x)+x)\n",
    "        all_y_cords.append((label_point[1::2]*scale_val_y)+y)\n",
    "\n",
    "\n",
    "\n",
    "    final_points_list = []\n",
    "    try:\n",
    "        for ii in range(len(all_x_cords)):\n",
    "            for a_x, a_y in zip(all_x_cords[ii], all_y_cords[ii]):\n",
    "                final_points_list.append([a_x, a_y])\n",
    "    except:\n",
    "        return final_points_list\n",
    "\n",
    "    return final_points_list\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(input_file)\n",
    "ret, frame = cap.read()\n",
    "height, width, channel = frame.shape\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "out = cv2.VideoWriter(output_filename, fourcc, 20.0, (width, height))\n",
    "\n",
    "\n",
    "frame_no = 0\n",
    "while cap.isOpened():\n",
    "\n",
    "    a = time.time()\n",
    "    \n",
    "    frame_no += 1\n",
    "    ret, frame = cap.read()\n",
    "    if frame_no > 75*30:\n",
    "        break\n",
    "    if frame_no in range(60*30, 75*30):\n",
    "        points = get_points_main(frame)\n",
    "\n",
    "        try:\n",
    "            overlay = frame.copy()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "        for point in points:\n",
    "\n",
    "            cv2.circle(frame, tuple(point), 3, (255, 255, 255), -1)\n",
    "            # cv2.line(frame, last_point, tuple(point), (0,0,255), thickness=1)\n",
    "            # cv2.putText(overlay, str(i), tuple(point), 1, 1, (255, 255, 255))\n",
    "\n",
    "        if len(points) != 0:\n",
    "            o_line_points = [[12,13], [13,11], [11,14], [14,12], [12,10], [11,10], [10,3], [12,5], [11,3], [10,5], [10,4], [10,2], [5,1], [1,4], [2,0], [0,3], [5,9], [9,8], [8,4], [2,6], [6,7], [7,3]]\n",
    "            num_face = len(points)//15\n",
    "\n",
    "            for i in range(num_face):\n",
    "                line_points = np.array(o_line_points) + (15*(i))\n",
    "\n",
    "                the_color = (189, 195, 199)\n",
    "\n",
    "                for ii in line_points:\n",
    "                    cv2.line(overlay, tuple(points[ii[0]]), tuple(points[ii[1]]), the_color, thickness=1)\n",
    "\n",
    "\n",
    "        opacity = 0.3\n",
    "        cv2.addWeighted(overlay, opacity, frame, 1 - opacity, 0, frame)\n",
    "\n",
    "        out.write(frame)\n",
    "        # cv2.imshow('frame',frame)\n",
    "        b = time.time()\n",
    "        print(str((b-a)))\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "           \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FOAUDoeHzdpT"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "For more details watch >> https://www.youtube.com/watch?v=vC3bTziLRTA\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "facialKeypointDetection_YT.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
